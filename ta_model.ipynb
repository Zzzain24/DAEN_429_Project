{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-A: head-only fine-tuning (best-by macro-F1)\n",
    "from pathlib import Path\n",
    "import json, numpy as np, torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# project paths (adjust if needed)\n",
    "ROOT = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "DATA_ROOT = ROOT / \"asl_alphabet_train\"\n",
    "ART = ROOT / \"artifacts\"\n",
    "CKPT = ROOT / \"checkpoints\"; CKPT.mkdir(exist_ok=True)\n",
    "RESULTS = ROOT / \"results\"; RESULTS.mkdir(exist_ok=True)\n",
    "\n",
    "SEED = 429\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 224\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    torch.mps.manual_seed(SEED)\n",
    "else:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb082a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load class mapping and split indices\n",
    "with open(ART / \"class_to_idx.json\") as f:\n",
    "    class_to_idx = json.load(f)\n",
    "classes = [c for c, _ in sorted(class_to_idx.items(), key=lambda kv: kv[1])]\n",
    "num_classes = len(classes)\n",
    "\n",
    "train_idx = np.load(ART / \"train_idx.npy\")\n",
    "val_idx   = np.load(ART / \"val_idx.npy\")\n",
    "print(\"Classes:\", num_classes, classes[:10], \"...\")\n",
    "\n",
    "# transforms (ImageNet stats)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# rebuild full dataset from folder structure\n",
    "full_ds = datasets.ImageFolder(root=DATA_ROOT, transform=tfm)\n",
    "# Minimal sanity: expected classes present\n",
    "assert set(class_to_idx.keys()).issubset(set(full_ds.classes)), \"Missing expected classes.\"\n",
    "\n",
    "# fixed split subsets\n",
    "train_ds = Subset(full_ds, train_idx.tolist())\n",
    "val_ds   = Subset(full_ds, val_idx.tolist())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Batches -> train:\", len(train_loader), \"val:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet-pretrained ResNet-18\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# replace classifier head to 27 outputs\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# freeze all backbone params\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "# Unfreeze ONLY the new head\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# keep frozen BatchNorms in eval to avoid running-stat drift\n",
    "def _bn_eval(m):\n",
    "    if isinstance(m, nn.BatchNorm2d): m.eval()\n",
    "model.apply(_bn_eval)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable params: {trainable:,} / {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d913ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=1e-3)\n",
    "\n",
    "# helper functions\n",
    "def _batch_correct(logits, y_true):\n",
    "    preds = logits.argmax(1)\n",
    "    correct = (preds == y_true).sum().item()\n",
    "    return preds, correct\n",
    "\n",
    "# evaluate with F1 score\n",
    "@torch.no_grad()\n",
    "def evaluate_with_f1(model, loader):\n",
    "    model.eval()\n",
    "    total, correct, running_loss = 0, 0, 0.0\n",
    "    all_pred, all_true = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds, corr = _batch_correct(logits, yb)\n",
    "        all_pred.extend(preds.cpu().tolist())\n",
    "        all_true.extend(yb.cpu().tolist())\n",
    "        correct += corr\n",
    "        total += xb.size(0)\n",
    "    acc = correct / total\n",
    "    macro_f1 = f1_score(all_true, all_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(all_true, all_pred, labels=list(range(num_classes)))\n",
    "    return running_loss / total, acc, macro_f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# extend if val F1 keeps improving\n",
    "EPOCHS = 10  \n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n",
    "\n",
    "best_val_f1 = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    tr_total, tr_correct, tr_running = 0, 0, 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_running += loss.item() * xb.size(0)\n",
    "        preds, corr = _batch_correct(logits, yb)\n",
    "        tr_correct += corr\n",
    "        tr_total += xb.size(0)\n",
    "\n",
    "    tr_loss = tr_running / tr_total\n",
    "    tr_acc  = tr_correct / tr_total\n",
    "\n",
    "    # validate (loss, acc, macro-F1)\n",
    "    va_loss, va_acc, va_f1, _ = evaluate_with_f1(model, val_loader)\n",
    "\n",
    "    # log\n",
    "    history[\"train_loss\"].append(tr_loss)\n",
    "    history[\"train_acc\"].append(tr_acc)\n",
    "    history[\"val_loss\"].append(va_loss)\n",
    "    history[\"val_acc\"].append(va_acc)\n",
    "    history[\"val_f1\"].append(va_f1)\n",
    "\n",
    "    # model selection by macro-F1\n",
    "    if va_f1 > best_val_f1:\n",
    "        best_val_f1 = va_f1\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "        tag = \"<= BEST\"\n",
    "    else:\n",
    "        tag = \"\"\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train: loss {tr_loss:.4f}, acc {tr_acc:.3f} | \"\n",
    "          f\"val: loss {va_loss:.4f}, acc {va_acc:.3f}, F1 {va_f1:.4f} {tag}\")\n",
    "\n",
    "# save best-by-F1 checkpoint\n",
    "best_path = CKPT / \"best_TA.pt\"\n",
    "torch.save(best_state, best_path)\n",
    "print(\"Saved best T-A to:\", best_path, \"| Best Val Macro-F1:\", f\"{best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf32f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training curves for plotting later\n",
    "import pandas as pd\n",
    "pd.DataFrame(history).to_csv(RESULTS / \"TA_history.csv\", index=False)\n",
    "\n",
    "# Confusion matrix for best checkpoint (on val)\n",
    "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "_, _, va_f1_best, cm_best = evaluate_with_f1(model, val_loader)\n",
    "np.save(RESULTS / \"TA_val_confusion_matrix.npy\", cm_best)\n",
    "print(\"Val macro-F1 (best):\", f\"{va_f1_best:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
