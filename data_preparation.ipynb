{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# adjust this to your dataset location\n",
    "DATA_ROOT = Path(\"./asl_alphabet_train\")\n",
    "ARTIFACTS = Path(\"./artifacts\")\n",
    "ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "SEED = 429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a54656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 87000\n",
      "29 Classes found: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for class_dir in sorted(DATA_ROOT.iterdir()):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "    label = class_dir.name\n",
    "    for img_path in class_dir.glob(\"*.jpg\"):\n",
    "        rows.append((str(img_path.resolve()), label))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"path\", \"label\"])\n",
    "print(\"Total images:\", len(df))\n",
    "print(f\"{len(df['label'].unique())} Classes found:\", sorted(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a32a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped classes: ['del', 'nothing']\n",
      "27 Classes kept: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space']\n"
     ]
    }
   ],
   "source": [
    "keep = [chr(c) for c in range(ord('A'), ord('Z')+1)] + ['space']\n",
    "drop = {'del', 'nothing'}\n",
    "\n",
    "df = df[~df['label'].isin(drop)]\n",
    "df = df[df['label'].isin(keep)].reset_index(drop=True)\n",
    "\n",
    "print(\"Dropped classes:\", sorted(drop))\n",
    "\n",
    "print(f\"{len(df['label'].unique())} Classes kept:\", sorted(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8a090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images after corrupt check: 81000\n"
     ]
    }
   ],
   "source": [
    "# check for corrupt images\n",
    "good_idx = []\n",
    "for i, p in enumerate(df['path']):\n",
    "    try:\n",
    "        with Image.open(p) as im:\n",
    "            im.verify()\n",
    "        good_idx.append(i)\n",
    "    except (UnidentifiedImageError, OSError):\n",
    "        pass\n",
    "\n",
    "df = df.iloc[good_idx].reset_index(drop=True)\n",
    "print(\"Images after corrupt check:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4265ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode lables to numeric ids and save\n",
    "classes = sorted(keep)\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "df['y'] = df['label'].map(class_to_idx)\n",
    "\n",
    "with open(ARTIFACTS / \"class_to_idx.json\", \"w\") as f:\n",
    "    json.dump(class_to_idx, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a8f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 64800, Val size: 16200\n"
     ]
    }
   ],
   "source": [
    "# split data into train and validation sets\n",
    "indices = np.arange(len(df))\n",
    "labels = df['y'].to_numpy()\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices, test_size=0.2, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "np.save(ARTIFACTS / \"train_idx.npy\", train_idx)\n",
    "np.save(ARTIFACTS / \"val_idx.npy\", val_idx)\n",
    "\n",
    "print(f\"Train size: {len(train_idx)}, Val size: {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d9dcae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved in: /Users/zainbharde/Documents/GitHub/Bharde_429_Final/artifacts\n"
     ]
    }
   ],
   "source": [
    "# save train and validation manifests\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_val   = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "df.to_csv(ARTIFACTS / \"manifest_filtered.csv\", index=False)\n",
    "df_train.to_csv(ARTIFACTS / \"train_manifest.csv\", index=False)\n",
    "df_val.to_csv(ARTIFACTS / \"val_manifest.csv\", index=False)\n",
    "\n",
    "print(\"Artifacts saved in:\", ARTIFACTS.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
